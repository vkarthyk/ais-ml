{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appyling NLP on the description field of the AIS data. All stopwords are removed and the words are vectorized. The target variable used for training is the Object Type that has been identified like malicious IP, email, URL etc.. Hence, this model is trying to predict the observable of the attack based on it's description. This is just a try to see how we can extract meaningful information from the description field of the AIS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('ais_data.csv', encoding = \"ISO-8859-1\")\n",
    "df2 = pd.DataFrame(df[['stix_header.description.0', 'indicators.observable.object.properties.xsi:type.0']])\n",
    "df2 = df2.fillna('')\n",
    "\n",
    "# I am only using the rows which contain this observable for training the model\n",
    "df2 = df2[df2['indicators.observable.object.properties.xsi:type.0'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can see 186 fields out of 225 are AddressObjectType. So the dataset is skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                   225\n",
       "unique                    5\n",
       "top       AddressObjectType\n",
       "freq                    186\n",
       "Name: indicators.observable.object.properties.xsi:type.0, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['indicators.observable.object.properties.xsi:type.0'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract IP addresses from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stix_header.description.0</th>\n",
       "      <th>indicators.observable.object.properties.xsi:type.0</th>\n",
       "      <th>ip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>On 06 January 2015, an organization in the aer...</td>\n",
       "      <td>URIObjectType</td>\n",
       "      <td>178.79.186.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A trusted third party has found these IP addre...</td>\n",
       "      <td>AddressObjectType</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>An organization in the Aerospace sector observ...</td>\n",
       "      <td>URIObjectType</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>On 5 April 2016, a trusted third-party provide...</td>\n",
       "      <td>DomainNameObjectType</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>DomainNameObjectType</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            stix_header.description.0  \\\n",
       "6   On 06 January 2015, an organization in the aer...   \n",
       "9   A trusted third party has found these IP addre...   \n",
       "13  An organization in the Aerospace sector observ...   \n",
       "15  On 5 April 2016, a trusted third-party provide...   \n",
       "20                                                      \n",
       "\n",
       "   indicators.observable.object.properties.xsi:type.0             ip  \n",
       "6                                       URIObjectType  178.79.186.55  \n",
       "9                                   AddressObjectType                 \n",
       "13                                      URIObjectType                 \n",
       "15                               DomainNameObjectType                 \n",
       "20                               DomainNameObjectType                 "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_ip(text):\n",
    "    try:\n",
    "        ip_candidates = re.findall(r\"\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b\", text.encode('utf-8'))\n",
    "        return ', '.join(ip_candidates)\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "df2['ip'] = df2['stix_header.description.0'].apply(lambda x: extract_ip(x))\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract length of the description field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stix_header.description.0</th>\n",
       "      <th>indicators.observable.object.properties.xsi:type.0</th>\n",
       "      <th>ip</th>\n",
       "      <th>description_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>On 06 January 2015, an organization in the aer...</td>\n",
       "      <td>URIObjectType</td>\n",
       "      <td>178.79.186.55</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A trusted third party has found these IP addre...</td>\n",
       "      <td>AddressObjectType</td>\n",
       "      <td></td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>An organization in the Aerospace sector observ...</td>\n",
       "      <td>URIObjectType</td>\n",
       "      <td></td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>On 5 April 2016, a trusted third-party provide...</td>\n",
       "      <td>DomainNameObjectType</td>\n",
       "      <td></td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>DomainNameObjectType</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            stix_header.description.0  \\\n",
       "6   On 06 January 2015, an organization in the aer...   \n",
       "9   A trusted third party has found these IP addre...   \n",
       "13  An organization in the Aerospace sector observ...   \n",
       "15  On 5 April 2016, a trusted third-party provide...   \n",
       "20                                                      \n",
       "\n",
       "   indicators.observable.object.properties.xsi:type.0             ip  \\\n",
       "6                                       URIObjectType  178.79.186.55   \n",
       "9                                   AddressObjectType                  \n",
       "13                                      URIObjectType                  \n",
       "15                               DomainNameObjectType                  \n",
       "20                               DomainNameObjectType                  \n",
       "\n",
       "    description_length  \n",
       "6                  291  \n",
       "9                  295  \n",
       "13                 252  \n",
       "15                 241  \n",
       "20                   0  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['description_length'] = df2['stix_header.description.0'].apply(len)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's remove stopwords. We can import a list of english stopwords from NLTK. Stopwords are the most commonly used English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'i',\n",
       " u'me',\n",
       " u'my',\n",
       " u'myself',\n",
       " u'we',\n",
       " u'our',\n",
       " u'ours',\n",
       " u'ourselves',\n",
       " u'you',\n",
       " u'your']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[0:10] # Show some stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     [06, January, 2015, organization, aerospace, s...\n",
       "9     [trusted, third, party, found, IP, addresses, ...\n",
       "13    [organization, Aerospace, sector, observed, re...\n",
       "15    [5, April, 2016, trusted, thirdparty, provided...\n",
       "20                                                   []\n",
       "Name: stix_header.description.0, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['stix_header.description.0'].head(5).apply(text_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each vector will have as many dimensions as there are unique words in the SMS corpus.  We will first use SciKit Learn's **CountVectorizer**. This model will convert a collection of text documents to a matrix of token counts.\n",
    "\n",
    "We can imagine this as a 2-Dimensional matrix. Where the 1-dimension is the entire vocabulary (1 row per word) and the other dimension are the actual documents, in this case a column per text message. \n",
    "\n",
    "For example:\n",
    "\n",
    "<table border = “1“>\n",
    "<tr>\n",
    "<th></th> <th>Message 1</th> <th>Message 2</th> <th>...</th> <th>Message N</th> \n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 1 Count</b></td><td>0</td><td>1</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 2 Count</b></td><td>0</td><td>0</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>...</b></td> <td>1</td><td>2</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word N Count</b></td> <td>0</td><td>1</td><td>...</td><td>1</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "Since there are so many messages, we can expect a lot of zero counts for the presence of that word in that document. Because of this, SciKit Learn will output a [Sparse Matrix](https://en.wikipedia.org/wiki/Sparse_matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(df2['stix_header.description.0'])\n",
    "\n",
    "# Print total number of vocab words\n",
    "print len(bow_transformer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are the features that the model has identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'0060, 045, 06, 10, 10063500, 10070166, 1015, 16, 2015, 20150826, 2016, 20161015, 20161017, 2016INDICATOR1WFQ1U, 2016INDICATOR3HIA6T, 2016INDICATOR47JTFP, 2016INDICATOR8TTBY, 2016INDICATOROZFTC, 25, 31, 32bit, 4, 42, 5, APT, Access, According, Active, Aerospace, Aircraft, Analysis, April, Association, Attempts, CIG, CISA, CSEC, Canada, Center, Circular, Colorado, Conficker, Cyber, DGAs, Dated, Directed, Directory, Donald, DustySky, EXEPROXY, Election, Environment, FIDELIS, IP, IPs, IPv4, Implant, Intrusion, January, Java, July, MIFR, Malicious, March, Multiplatform, None, OPM, Operations, Owners, PHP, Phishing, Pilots, PresidentElect, Presidential, Remote, Reported, Results, Scans, Secretary, Security, Spear, State, States, Submission, Test, Tool, Traversal, Treasury, Trojans, Trump, UK, URL, USCERT, United, Webform, ability, activity, actor, additional, address, addresses, advanced, aerospace, algorithm, alleged, analysis, artifact, artifacts, associated, available, aviation, aware, became, campaign, campaigns, capabilities, code, command, complete, complexity, compromised, computer, conducting, connected, contact, contained, contains, control, coordinated, credible, defend, derived, description, detect, determined, different, document, domain, domains, download, due, email, emails, end, even, executable, exploit, file, files, financial, found, generation, group, help, hole, hoppoint, host, hosting, hours, http1787918655JqueryJqueryphp, httpsotxalienvaultcompulse583cc3d8b85a4202020c613f, httpssecurelistcomblogresearch71713darkhotelsattacksin2015, httpswwwvolexitycomblog20161109powerdukepostelectionspearphishingcampaignstargetingthinktanksandngos, httpwwwwelivesecuritycom20151216nemucodmalwarespreadsransomwareteslacryptaroundworld, identified, identity, incident, incomplete, indicator, indicators, infected, information, initially, installer, intended, known, launched, legitimate, likely, links, list, located, malicious, malware, mask, may, mimicking, myIDcare, nations, nodes, noticed, observed, obtained, occurring, one, organization, originating, owner, part, party, persistent, phishing, please, preliminary, previously, provided, receive, received, redirected, redirects, related, report, reporting, required, sector, send, sender, series, several, sites, six, source, spam, spear, stanfordedu, submission, submitted, suspicious, targeted, techniques, third, thirdparty, threat, threats, tool, tries, trusted, two, updated, updates, used, uses, using, variant, version, wake, watering, website, wellplanned, windows7000, wwwaopacouk, wwwcascadeaerospacecom, wwwimpgroupcom'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(bow_transformer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (225, 253)\n",
      "Amount of Non-Zero occurences:  422\n",
      "sparsity: 0.74%\n"
     ]
    }
   ],
   "source": [
    "messages_bow = bow_transformer.transform(df2['stix_header.description.0'])\n",
    "print 'Shape of Sparse Matrix: ', messages_bow.shape\n",
    "print 'Amount of Non-Zero occurences: ', messages_bow.nnz\n",
    "print 'sparsity: %.2f%%' % (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     225\n",
       "unique     32\n",
       "top          \n",
       "freq      185\n",
       "Name: stix_header.description.0, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['stix_header.description.0'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 253)\n"
     ]
    }
   ],
   "source": [
    "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "print messages_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "threat_detect_model = MultinomialNB().fit(messages_tfidf, df2['indicators.observable.object.properties.xsi:type.0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_predictions = threat_detect_model.predict(messages_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "     AddressObjectType       0.83      1.00      0.91       186\n",
      "  DomainNameObjectType       0.00      0.00      0.00        22\n",
      "EmailMessageObjectType       0.00      0.00      0.00         1\n",
      "        FileObjectType       0.00      0.00      0.00         4\n",
      "         URIObjectType       0.00      0.00      0.00        12\n",
      "\n",
      "           avg / total       0.68      0.83      0.75       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print classification_report(df2['indicators.observable.object.properties.xsi:type.0'], all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model achieves 68% precision and 83% recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Right now the model predicts all classes to be AddressObjectType as the data is very biased and does not have many rows with the other target variables. But the model might perform better on the entire AIS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
